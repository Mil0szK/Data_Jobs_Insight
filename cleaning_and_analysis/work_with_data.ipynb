{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-29T09:18:40.535245Z",
     "start_time": "2025-03-29T09:18:40.148963Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "from json import loads\n",
    "from requests import get\n",
    "import re\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# connect to the database\n",
    "\n",
    "dotenv_path = os.path.join(\"..\", \"scraping\", \".env\")\n",
    "load_dotenv(dotenv_path)\n",
    "DATABASE_URL = f\"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "query = \"SELECT * FROM job_postings WHERE description IS NOT NULL;\"\n",
    "original_df = pd.read_sql(query, engine)\n",
    "df = original_df.copy()\n",
    "\n",
    "query2 =  \"\"\"\n",
    "    SELECT job_sources.*\n",
    "    FROM job_sources \n",
    "    INNER JOIN job_postings AS j \n",
    "    ON job_sources.job_id = j.job_id\n",
    "    WHERE j.description IS NOT NULL;\n",
    "\"\"\"\n",
    "original_df2 = pd.read_sql(query2, engine)\n",
    "df2 = original_df2.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-29T09:18:41.399443Z",
     "start_time": "2025-03-29T09:18:40.536236Z"
    }
   },
   "id": "8a6f9c34488013ab",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      id      job_id                                          title  \\\n0  14048  4115475043         Senior AI Engineer proficient in Swift   \n1  18412  4130485010                               Node.js Engineer   \n2      8  4158353862    Junior Data Scientist (Business Operations)   \n3  14872  4056210173  Senior Data Integration Engineer (Databricks)   \n4   8155  4112977117                    Lider/ka zespołu Google Ads   \n\n                                  location salary experience_level job_type  \\\n0    Warsaw, Mazowieckie, Poland (On-site)   None             None     None   \n1     Warsaw, Mazowieckie, Poland (Hybrid)   None             None     None   \n2    Warsaw, Mazowieckie, Poland (On-site)   None             None     None   \n3                          Poland (Remote)   None             None     None   \n4  Poznań, Wielkopolskie, Poland (On-site)   None             None     None   \n\n  employment_type                                        description  \\\n0            None  We are seeking a highly motivated and experien...   \n1            None   Ring Publishing: (http://ringpublishing.com) ...   \n2            None   Job Description: The Business Operations Team...   \n3            None  We are looking for a Senior Data Integration E...   \n4            None   Widoczni - miejsce dla ludzi nastawionych na ...   \n\n  responsibilities requirements skills benefits                       company  \\\n0             None         None   None     None            AIDA projektai, MB   \n1             None         None   None     None  Ringier Axel Springer Polska   \n2             None         None   None     None                          Wolt   \n3             None         None   None     None                  EPAM Systems   \n4             None         None   None     None                      widoczni   \n\n                                description_criteria  \\\n0  Seniority level Mid-Senior level Employment ty...   \n1  Seniority level Not Applicable Employment type...   \n2  Seniority level Mid-Senior level Employment ty...   \n3  Seniority level Mid-Senior level Employment ty...   \n4  Seniority level Executive Employment type Full...   \n\n                                      description_en  \n0                                               None  \n1  Ring Publishing: (http: // Ringpublishing com)...  \n2                                               None  \n3                                               None  \n4  Visible - a place for people focused on succes...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>job_id</th>\n      <th>title</th>\n      <th>location</th>\n      <th>salary</th>\n      <th>experience_level</th>\n      <th>job_type</th>\n      <th>employment_type</th>\n      <th>description</th>\n      <th>responsibilities</th>\n      <th>requirements</th>\n      <th>skills</th>\n      <th>benefits</th>\n      <th>company</th>\n      <th>description_criteria</th>\n      <th>description_en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14048</td>\n      <td>4115475043</td>\n      <td>Senior AI Engineer proficient in Swift</td>\n      <td>Warsaw, Mazowieckie, Poland (On-site)</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>We are seeking a highly motivated and experien...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>AIDA projektai, MB</td>\n      <td>Seniority level Mid-Senior level Employment ty...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18412</td>\n      <td>4130485010</td>\n      <td>Node.js Engineer</td>\n      <td>Warsaw, Mazowieckie, Poland (Hybrid)</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Ring Publishing: (http://ringpublishing.com) ...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Ringier Axel Springer Polska</td>\n      <td>Seniority level Not Applicable Employment type...</td>\n      <td>Ring Publishing: (http: // Ringpublishing com)...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>4158353862</td>\n      <td>Junior Data Scientist (Business Operations)</td>\n      <td>Warsaw, Mazowieckie, Poland (On-site)</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Job Description: The Business Operations Team...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Wolt</td>\n      <td>Seniority level Mid-Senior level Employment ty...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14872</td>\n      <td>4056210173</td>\n      <td>Senior Data Integration Engineer (Databricks)</td>\n      <td>Poland (Remote)</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>We are looking for a Senior Data Integration E...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>EPAM Systems</td>\n      <td>Seniority level Mid-Senior level Employment ty...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8155</td>\n      <td>4112977117</td>\n      <td>Lider/ka zespołu Google Ads</td>\n      <td>Poznań, Wielkopolskie, Poland (On-site)</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Widoczni - miejsce dla ludzi nastawionych na ...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>widoczni</td>\n      <td>Seniority level Executive Employment type Full...</td>\n      <td>Visible - a place for people focused on succes...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-29T09:18:41.411801Z",
     "start_time": "2025-03-29T09:18:41.400512Z"
    }
   },
   "id": "5a0a7057e9221e5b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   id      job_id    source                                        job_url  \\\n0   1  4158353862  LinkedIn  https://www.linkedin.com/jobs/view/4158353862   \n1   2  4138407547  LinkedIn  https://www.linkedin.com/jobs/view/4138407547   \n2   3  4144364769  LinkedIn  https://www.linkedin.com/jobs/view/4144364769   \n3   4  4083706042  LinkedIn  https://www.linkedin.com/jobs/view/4083706042   \n4   5  4154765012  LinkedIn  https://www.linkedin.com/jobs/view/4154765012   \n\n  date_posted  is_active  \n0  2025-02-21       True  \n1  2025-02-21       True  \n2  2025-02-21       True  \n3  2025-02-21       True  \n4  2025-02-21       True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>job_id</th>\n      <th>source</th>\n      <th>job_url</th>\n      <th>date_posted</th>\n      <th>is_active</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>4158353862</td>\n      <td>LinkedIn</td>\n      <td>https://www.linkedin.com/jobs/view/4158353862</td>\n      <td>2025-02-21</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4138407547</td>\n      <td>LinkedIn</td>\n      <td>https://www.linkedin.com/jobs/view/4138407547</td>\n      <td>2025-02-21</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4144364769</td>\n      <td>LinkedIn</td>\n      <td>https://www.linkedin.com/jobs/view/4144364769</td>\n      <td>2025-02-21</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4083706042</td>\n      <td>LinkedIn</td>\n      <td>https://www.linkedin.com/jobs/view/4083706042</td>\n      <td>2025-02-21</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>4154765012</td>\n      <td>LinkedIn</td>\n      <td>https://www.linkedin.com/jobs/view/4154765012</td>\n      <td>2025-02-21</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-29T09:18:41.418368Z",
     "start_time": "2025-03-29T09:18:41.412964Z"
    }
   },
   "id": "5da08937b48dae01",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unknown\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-29T09:18:41.421275Z",
     "start_time": "2025-03-29T09:18:41.419020Z"
    }
   },
   "id": "41165e08935242ae",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def split_text(text, max_length=500):\n",
    "    \"\"\"Splits text into chunks, ensuring each is under the max_length.\"\"\"\n",
    "    sentences = re.split(r'\\.\\s*', text)\n",
    "    chunks = []\n",
    "    temp_chunk = \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if temp_chunk and len(temp_chunk) + len(sentence) + 1 > max_length:\n",
    "            chunks.append(temp_chunk.strip())\n",
    "            temp_chunk = sentence\n",
    "        else:\n",
    "            temp_chunk = f\"{temp_chunk} {sentence}\".strip() if temp_chunk else sentence\n",
    "    if temp_chunk:\n",
    "        chunks.append(temp_chunk.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def translate_text(text):\n",
    "    \"\"\"Translates text using the free Google API.\"\"\"\n",
    "    url = f\"https://translate.googleapis.com/translate_a/single?client=gtx&dt=t&sl=pl&tl=en&q={text}\"\n",
    "    try:\n",
    "        response = get(url)\n",
    "        translated_json = loads(response.text)\n",
    "        return translated_json[0][0][0] if translated_json else text\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating: {e}\")\n",
    "        return text\n",
    "\n",
    "def translate_full_text(text):\n",
    "    \"\"\"Splits, translates, and reconstructs the translated text.\"\"\"\n",
    "    chunks = split_text(text)\n",
    "    translated_chunks = [translate_text(chunk) for chunk in chunks]\n",
    "    return \" \".join(translated_chunks)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-29T09:18:41.425939Z",
     "start_time": "2025-03-29T09:18:41.422074Z"
    }
   },
   "id": "bb9e48e9d8942358",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔸 Translating chunk 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [05:38<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 saved to database.\n",
      "\n",
      "🔸 Translating chunk 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [05:43<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 2 saved to database.\n",
      "\n",
      "🔸 Translating chunk 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [27:36<00:00,  4.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 3 saved to database.\n",
      "\n",
      "🔸 Translating chunk 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 214/366 [21:11<16:47,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [38:00<00:00,  6.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 4 saved to database.\n",
      "\n",
      "🔸 Translating chunk 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 42/366 [03:19<13:44,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [28:20<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 5 saved to database.\n",
      "\n",
      "🔸 Translating chunk 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/366 [01:13<1:48:04, 18.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 161/366 [11:43<12:36,  3.69s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [25:18<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 6 saved to database.\n",
      "\n",
      "🔸 Translating chunk 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [09:10<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 7 saved to database.\n",
      "\n",
      "🔸 Translating chunk 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 188/366 [06:31<09:37,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 298/366 [13:19<03:39,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [17:24<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 8 saved to database.\n",
      "\n",
      "🔸 Translating chunk 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [19:31<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 9 saved to database.\n",
      "\n",
      "🔸 Translating chunk 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [20:51<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 10 saved to database.\n",
      "\n",
      "🔸 Translating chunk 11/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [21:03<00:00,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 11 saved to database.\n",
      "\n",
      "🔸 Translating chunk 12/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [18:15<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 12 saved to database.\n",
      "\n",
      "🔸 Translating chunk 13/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [19:56<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 13 saved to database.\n",
      "\n",
      "🔸 Translating chunk 14/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [20:57<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 14 saved to database.\n",
      "\n",
      "🔸 Translating chunk 15/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [19:43<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 15 saved to database.\n",
      "\n",
      "🔸 Translating chunk 16/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [21:34<00:00,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 16 saved to database.\n",
      "\n",
      "🔸 Translating chunk 17/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [22:42<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 17 saved to database.\n",
      "\n",
      "🔸 Translating chunk 18/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [30:24<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 18 saved to database.\n",
      "\n",
      "🔸 Translating chunk 19/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 183/366 [17:37<23:04,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 366/366 [30:23<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 19 saved to database.\n",
      "\n",
      "🔸 Translating chunk 20/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [21:27<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 20 saved to database.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sqlalchemy.exc import OperationalError\n",
    "import time\n",
    "import math\n",
    "tqdm.pandas()\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"ALTER TABLE job_postings ADD COLUMN IF NOT EXISTS description_en TEXT;\"))\n",
    "    connection.commit()\n",
    "    \n",
    "df[\"language\"] = df[\"description\"].apply(detect_language)\n",
    "df[\"description_en\"] = df.get(\"description_en\", pd.Series([None]*len(df)))\n",
    "\n",
    "df_to_translate = df[(df[\"language\"] == \"pl\") & (df[\"description_en\"].isnull())].copy()\n",
    "total = len(df_to_translate)\n",
    "chunk_size = math.ceil(total / 20)\n",
    "\n",
    "for i in range(0, total, chunk_size):\n",
    "    chunk = df_to_translate.iloc[i:i+chunk_size].copy()\n",
    "    print(f\"\\n🔸 Translating chunk {i//chunk_size + 1}/10\")\n",
    "\n",
    "    chunk[\"translated_description\"] = chunk[\"description\"].progress_apply(translate_full_text)\n",
    "\n",
    "    # Save to DB\n",
    "    for _, row in chunk.iterrows():\n",
    "        try:\n",
    "            with engine.begin() as conn:\n",
    "                conn.execute(\n",
    "                    text(\"UPDATE job_postings SET description_en = :desc_en WHERE job_id = :job_id\"),\n",
    "                    {\"desc_en\": row[\"translated_description\"], \"job_id\": row[\"job_id\"]}\n",
    "                )\n",
    "        except OperationalError as e:\n",
    "            print(f\"OperationalError for job_id={row['job_id']}: {e}\")\n",
    "            time.sleep(3)\n",
    "\n",
    "    print(f\"Chunk {i//chunk_size + 1} saved to database.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-29T16:25:06.432991Z",
     "start_time": "2025-03-29T09:18:41.426600Z"
    }
   },
   "id": "f3d347c1548f64da",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-29T16:25:06.435600Z",
     "start_time": "2025-03-29T16:25:06.433842Z"
    }
   },
   "id": "6b712061ac21379b",
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
